{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f604b16-52ff-4903-bdba-25ff5a644a44",
   "metadata": {},
   "source": [
    "#### In this notebook: We will try to extract from the files.tar in the tar_folder all the csv.gz files and save them in the folder of csv_files :     \n",
    "https://chat.openai.com/share/0f635485-122d-41d3-8d32-7416801992b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1a071cf-a133-4f60-93f4-b843af8e29d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "import pandas as pd\n",
    "import importlib\n",
    "import tarfile\n",
    "from collections import Counter\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "src_path = os.path.join(current_dir,\"src\") \n",
    "dataLoadingDirectory = os.path.join(current_dir,\"data\",\"raw\",\n",
    "                                    \"flash_crash_DJIA\",\"tar_files\")\n",
    "dataSavingDirectory  = os.path.join(current_dir,\"data\",\"raw\",\n",
    "                                    \"flash_crash_DJIA\",\"csv_files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c752b7e-ffb5-4905-ae04-5139b6cbc114",
   "metadata": {},
   "source": [
    "#### Checking .tar file names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "963ed05d-4475-496a-ae55-b295020c8cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WMT.N-2010.tar', 'AMGN.OQ-2010.tar', 'RTX.N-2010.tar', 'IBM.N-2010.tar', 'UTX.N-2010.tar', 'NKE.N-2010.tar', 'VZ.N-2010.tar', 'KO.N-2010.tar', 'XOM.N-2010.tar', 'GS.N-2010.tar', 'JPM.N-2010.tar', 'AXP.N-2010.tar', 'MRK.N-2010.tar', 'WBA.OQ-2010.tar', 'CAT.N-2010.tar', 'DOW.N-2010.tar', 'V.N-2010.tar', 'CVX.N-2010.tar', 'PFE.N-2010.tar', 'JNJ.N-2010.tar', 'MMM.N-2010.tar', 'TRV.N-2010.tar', 'CSCO.OQ-2010.tar', 'PG.N-2010.tar', 'HD.N-2010.tar', 'BA.N-2010.tar', 'MSFT.OQ-2010.tar', 'UNH.N-2010.tar', 'MCD.N-2010.tar', 'INTC.OQ-2010.tar', 'AAPL.OQ-2010.tar']\n"
     ]
    }
   ],
   "source": [
    "## Listing the .tar file names \n",
    "print(os.listdir(dataLoadingDirectory))\n",
    "## Storing the .tar files paths \n",
    "tar_files = [os.path.join(dataLoadingDirectory,tar_file) for tar_file in \n",
    "             os.listdir(dataLoadingDirectory) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1e6a1-9111-4ee4-a4a9-7316e8f762a5",
   "metadata": {},
   "source": [
    "#### Inspecting the type of files stored in each tar file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f9e513-85c0-4df9-a328-d42d9755e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to list file types in a tar archive\n",
    "def list_file_types_in_tar(tar_path):\n",
    "    file_types = []\n",
    "    with tarfile.open(tar_path, \"r\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.isfile():\n",
    "                _, ext = os.path.splitext(member.name)\n",
    "                file_types.append(ext.lower())\n",
    "    return file_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c6ed7ba-7510-4819-b896-56c476f156c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Different types of files given are : Counter({'.gz': 16182})\n"
     ]
    }
   ],
   "source": [
    "# Simulating the processing of tar files\n",
    "file_types_counter = Counter()\n",
    "for tar_file in tar_files:\n",
    "    # In an actual implementation, 'tar_file' would be the path to the .tar file\n",
    "    file_types = list_file_types_in_tar(tar_file)  # This would extract file types from the actual .tar file\n",
    "    file_types_counter.update(file_types)\n",
    "print(f\"The Different types of files given are : {file_types_counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e56da-3335-4538-8fd2-8898044aa975",
   "metadata": {},
   "source": [
    "#### Discussion: \n",
    "All the files stored in the .tar files are .gz files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413bbeaa-7efa-49de-878e-f704181a66ed",
   "metadata": {},
   "source": [
    "#### Next step: For each tar file : Create a folder with its name and extract the files inside it, the all folders will be saved in general folder csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ca44427-34bc-4934-b6bb-ac4a27c74457",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tar_file in tar_files:\n",
    "    # Extract the name of the .tar file without extension to use as directory name\n",
    "    dir_name = os.path.splitext(os.path.basename(tar_file))[0]\n",
    "    dir_path = os.path.join(dataSavingDirectory, dir_name)\n",
    "\n",
    "    # Create a directory for extracted files\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    # Open the .tar file\n",
    "    with tarfile.open(tar_file, \"r\") as tar:\n",
    "        # Extract each file directly, ignoring the internal directory structure\n",
    "        for member in tar.getmembers():\n",
    "            if member.isfile():\n",
    "                member.name = os.path.basename(member.name)  # Remove the internal directory structure\n",
    "                tar.extract(member, dir_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099d049a-dd02-4dea-8d98-d958ccba90c1",
   "metadata": {},
   "source": [
    "#### Example of Reading a csv.gz files \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecf75e83-2bee-49b9-b23e-b5197882f6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ilyesbenayed/Desktop/Big data/data/raw/flash_crash_DJIA/csv_files/GS.N-2010\n"
     ]
    }
   ],
   "source": [
    "directory = os.listdir(dataSavingDirectory)[0]\n",
    "directory = os.path.join(dataSavingDirectory,directory)\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf89b339-1502-42a4-8fb7-a3048b511825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2010-08-26-GS.N-bbo.csv.gz', '2010-01-27-GS.N-trade.csv.gz', '2010-07-06-GS.N-trade.csv.gz', '2010-11-25-GS.N-bbo.csv.gz', '2010-07-16-GS.N-bbo.csv.gz']\n"
     ]
    }
   ],
   "source": [
    "### Geting the file names : \n",
    "print(os.listdir(directory)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e14f8-a8bb-4ef0-9ad1-03ff41bd20af",
   "metadata": {},
   "source": [
    "#### Discussion : It turns out that we have trade and bbo files , thus the next step is to save them seperately each in its corresponding folder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5c7c9-af1a-4448-bee3-047451136401",
   "metadata": {},
   "source": [
    "### Making trade and boo folder for each stock : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6da1b26a-9f09-4afd-8b8d-d291f7fe417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [os.path.join(dataSavingDirectory,\n",
    "                            directory) for directory in\n",
    "               os.listdir(dataSavingDirectory)]\n",
    "trade_directories = [os.path.join(directory,\"trade\") for directory in directories]\n",
    "bbo_directories = [os.path.join(directory,\"bbo\") for directory in directories]\n",
    "### Creating these directories if not existed yet : \n",
    "for trade_dir in trade_directories:\n",
    "    if not os.path.exists(trade_dir):\n",
    "        os.makedirs(trade_dir)\n",
    "for bbo_dir in bbo_directories:\n",
    "    if not os.path.exists(bbo_dir):\n",
    "        os.makedirs(bbo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03392529-483c-4f0a-934e-fcc8d79538be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We will iterate over each directroy : \n",
    "for directory in directories:\n",
    "    trade_dir  = os.path.join(directory,\"trade\")\n",
    "    bbo_dir    = os.path.join(directory,\"bbo\")\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv.gz\"):\n",
    "            if 'trade' in filename:\n",
    "            # Move trade files to the trade directory\n",
    "                shutil.move(os.path.join(directory, filename), os.path.join(trade_dir, filename))\n",
    "            elif 'bbo' in filename:\n",
    "            # Move bbo files to the bbo directory\n",
    "                shutil.move(os.path.join(directory, filename), os.path.join(bbo_dir, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354306f7-93f8-4fd7-acaa-e2d9d7dd128d",
   "metadata": {},
   "source": [
    "### Last Step: \n",
    "Exploring the csv.gz files (trade and bbo): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60b54f10-b426-404d-81e1-0c2ecccd47d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ilyesbenayed/Desktop/Big data/data/raw/flash_crash_DJIA/csv_files/GS.N-2010/trade\n",
      "         xltime  trade-price  trade-volume trade-stringflag  \\\n",
      "0  40205.604499       150.75        122600          auction   \n",
      "1  40205.604500       150.80           100    uncategorized   \n",
      "2  40205.604500       150.80           100    uncategorized   \n",
      "3  40205.604500       150.80           100    uncategorized   \n",
      "\n",
      "                                       trade-rawflag  \n",
      "0  [CTS_QUAL       ]O                            ...  \n",
      "1  [CTS_QUAL       ]                             ...  \n",
      "2  [CTS_QUAL       ]                             ...  \n",
      "3  [CTS_QUAL       ]                             ...  \n"
     ]
    }
   ],
   "source": [
    "## Example of trade file : \n",
    "trade_dir = trade_directories[0]\n",
    "trade_file = os.listdir(trade_dir)[0]\n",
    "# Using gzip.open to decompress the file and read it with pandas\n",
    "with gzip.open(os.path.join(trade_dir,trade_file), 'rt') as file:\n",
    "    df = pd.read_csv(file)\n",
    "print(df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02f694ab-68a2-4599-a1f5-7fb12b6d39e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         xltime  bid-price  bid-volume  ask-price  ask-volume\n",
      "0  40416.562628     144.70           1     144.93           1\n",
      "1  40416.562628     144.76           1     144.93           1\n",
      "2  40416.562628     144.76           2     144.93           1\n",
      "3  40416.562628     144.76           2     144.93           2\n"
     ]
    }
   ],
   "source": [
    "## Example of bbo file : \n",
    "bbo_dir = bbo_directories[0]\n",
    "bbo_file = os.listdir(bbo_dir)[0]\n",
    "# Using gzip.open to decompress the file and read it with pandas\n",
    "with gzip.open(os.path.join(bbo_dir,bbo_file), 'rt') as file:\n",
    "    df = pd.read_csv(file)\n",
    "print(df.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7c7287-031b-4037-8645-e2b1e9e7cacf",
   "metadata": {},
   "source": [
    "#### Last step: Regrouping csv files by month : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a49d47da-a2ee-49d4-bee3-1735f787ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_example = os.listdir(trade_directories[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06092e92-8755-481b-bff8-87f037692449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010_01'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_date = file_example.split('-')[:2]\n",
    "\"_\".join(part_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "63f5cdf9-4d95-4a68-b9be-ff394dc6ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFoldersGroupingYnMonthfiles(directories):\n",
    "    for dir in directories:\n",
    "        files = os.listdir(dir)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(dir, file)\n",
    "            # Check if the path is a file\n",
    "            if os.path.isfile(file_path):\n",
    "                date_part = file.split(\"-\")[:2]  # Taking the year and month\n",
    "                date_folder = \"_\".join(date_part)\n",
    "                date_dir = os.path.join(dir, date_folder)\n",
    "                if not os.path.exists(date_dir):\n",
    "                    os.makedirs(date_dir)\n",
    "                \n",
    "                # Construct the destination path\n",
    "                dest_path = os.path.join(date_dir, file)   \n",
    "        \n",
    "                # Move the file\n",
    "                shutil.move(file_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f34e630d-c743-4151-9e4b-be20746b30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "createFoldersGroupingYnMonthfiles(trade_directories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "780e84d9-b4c2-4f80-8644-40d4c82f1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "createFoldersGroupingYnMonthfiles(bbo_directories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a74054e-8d27-4540-9327-3049aa419593",
   "metadata": {},
   "source": [
    "## Conclusion of this Notebook: \n",
    "In this notebook we started from .tar files that were located in folder .tar files, the first thing we did is to explore the contents of the different tar files : we find out all were .gz files: For each tar file  we created its corresponding folder inside csv_file folder , after exploring the names of the gz files, we noticed there were trade and bbo files, as a second step, for each stock, we made a directory of trade regrouping the csv.gz trade files and and a bbo directory regrouping the csv.gz bbo (Best bid and offer ) files, we made in this notebook an inital exploration of a random trade file and a random bbo file, as a final step: We regroup files based on the year and month: Thus the final  structure is:    \n",
    "csv_files : Directoriy --> Directory for each stock ---> trade and boo directories --> year&month directories --> csv.gz files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a3d46d-3f8c-497e-921f-b757444f083a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
